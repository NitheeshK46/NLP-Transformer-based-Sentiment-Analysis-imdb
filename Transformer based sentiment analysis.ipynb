{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI\n",
        "\n",
        "Generative AI encompasses artificial intelligence techniques aimed at producing new content, such as text, images, audio, or video, that resembles or is inspired by existing data. These models learn patterns from training data and create new data samples that emulate these patterns.."
      ],
      "metadata": {
        "id": "2jk-hk75buMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the IMDB Dataset\n",
        "\n",
        "The dataset consists of movie reviews from IMDB, commonly used for sentiment analysis tasks. It includes labeled data where reviews are classified as either positive or negative sentiment."
      ],
      "metadata": {
        "id": "kqWWtMOEbx37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lx2HpM2bPYa",
        "outputId": "3cc17c65-4b5f-4a9f-a58d-26b5fc5770e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-07 01:43:23--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  41.1MB/s    in 2.0s    \n",
            "\n",
            "2024-08-07 01:43:25 (41.1 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The command `!tar -xf aclImdb_v1.tar.gz` extracts the contents of the `aclImdb_v1.tar.gz` archive file in the current directory."
      ],
      "metadata": {
        "id": "yRYynY06cOvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "hKiPp7GVcAE5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Generation in Keras"
      ],
      "metadata": {
        "id": "9nyOGb1ncWNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow .keras import layers\n",
        "dataset = keras.utils.text_dataset_from_directory(\n",
        "   'aclImdb',batch_size = 256, label_mode = None)\n",
        "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, '<br />', ' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MPSA3CCcbq_",
        "outputId": "51e8fa2c-3506-40ea-e94c-cb54c0654ecd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100006 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc0mWL1wcgE6",
        "outputId": "a20e04e0-85c9-433a-df67-a1255a262dd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Vectorization"
      ],
      "metadata": {
        "id": "een41ikgckqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "sequence_length = 100\n",
        "vocab_size = 15000\n",
        "text_vectorization =  TextVectorization (\n",
        "    max_tokens = vocab_size,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = sequence_length,)\n",
        "text_vectorization.adapt(dataset)"
      ],
      "metadata": {
        "id": "ISuJ0OXZckIs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using a TextVectorization layer to create a language modeling dataset"
      ],
      "metadata": {
        "id": "L5j_-9-ucrAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "    vectorized_sequences = text_vectorization(text_batch)\n",
        "    # Prepare input data (x) by excluding the last element of each sequence\n",
        "    x = vectorized_sequences[:, :-1]\n",
        "    # Prepare target data (y) by excluding the first element of each sequence\n",
        "    y = vectorized_sequences[:, 1:]\n",
        "    # Return the prepared input and target data\n",
        "    return x, y\n",
        "\n",
        "# Apply the prepare_lm_dataset function to each element in the dataset\n",
        "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)\n"
      ],
      "metadata": {
        "id": "-DWOP6ONcu6g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer-Based Sequence to Sequence Model"
      ],
      "metadata": {
        "id": "EYlByYoTcyfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "-d_PG_uNc52x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `TransformerEncoder` class implements a transformer encoder layer with multi-head attention, feed-forward network, and residual connections with layer normalization."
      ],
      "metadata": {
        "id": "E2mqkgePdGTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Multi-head attention layer\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Feed-forward network\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            layers.Dense(dense_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        # Layer normalization layers\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]  # Adjust mask shape for attention\n",
        "\n",
        "        # Apply multi-head attention\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=mask\n",
        "        )\n",
        "\n",
        "        # Apply residual connection and layer normalization\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "\n",
        "        # Apply feed-forward network\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "\n",
        "        # Apply another residual connection and layer normalization\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "R8kj3tlndK6S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a text generation callback for a Keras model that generates text based on a given prompt at the end of each epoch, using specified temperatures to control the randomness of predictions."
      ],
      "metadata": {
        "id": "q9FRpQwddWc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self, prompt, generate_length, model_input_length, temperatures=(1.,), print_freq=1):\n",
        "        super().__init__()\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.model_input_length = model_input_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_freq = print_freq\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.print_freq != 0:\n",
        "            return\n",
        "\n",
        "        for temperature in self.temperatures:\n",
        "            print(f\"== Generating with temperature {temperature}\")\n",
        "            sentence = self.prompt\n",
        "            for i in range(self.generate_length):\n",
        "                tokenized_sentence = text_vectorization([sentence])\n",
        "                predictions = self.model(tokenized_sentence)\n",
        "                next_token = sample_next(predictions[0, i, :], temperature)\n",
        "                sampled_token = tokens_index[next_token]\n",
        "                sentence += \" \" + sampled_token\n",
        "            print(sentence)"
      ],
      "metadata": {
        "id": "ClkEoYwddQHF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code defines a Keras model with an input layer, a positional embedding layer, a transformer encoder layer, and a dense output layer with softmax activation for text generation or sequence prediction."
      ],
      "metadata": {
        "id": "1ZEd0cIwdh7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Correct way: Use a Lambda layer to wrap the TensorFlow operation\n",
        "        return keras.layers.Lambda(lambda x: tf.math.not_equal(x, 0))(inputs)\n",
        "\n",
        "# Example usage in a model\n",
        "sequence_length = 100\n",
        "vocab_size = 15000\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 2\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLM-wiH0dceI",
        "outputId": "ab8bbcb6-9dc2-44b4-adf3-c49630a286bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'transformer_encoder' (of type TransformerEncoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code compiles the Keras model using the RMSprop optimizer and sparse categorical cross-entropy loss function for training."
      ],
      "metadata": {
        "id": "SwTrL4eSdu2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        " loss=\"sparse_categorical_crossentropy\",\n",
        " optimizer=\"rmsprop\",\n",
        ")"
      ],
      "metadata": {
        "id": "JzA_tLesdsx1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        " prompt,\n",
        " generate_length=50,\n",
        " model_input_length=sequence_length,\n",
        " temperatures=(0.2, 0.5, 1.0, 1.5))"
      ],
      "metadata": {
        "id": "6pjk9fdRenda"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(lm_dataset, epochs=10, callbacks=[text_gen_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6EWdysIepjs",
        "outputId": "7c76c432-bb60-4810-970f-86d16efc822f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - loss: 6.1708== Generating with temperature 0.2\n",
            "This movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this this movie movie this\n",
            "== Generating with temperature 0.5\n",
            "This movie movie this this movie movie this this movie movie this this movie i this dont movie this this movie this it movie this that movie this this movie movie this it movie this this movie movie this this movie movie this this movie movie it this it movie this this\n",
            "== Generating with temperature 1.0\n",
            "This movie it as make common this parts movie this  its neighbours this movie shark episode an entertainment it out of a bad hollywood andor this movie you would laugh                     \n",
            "== Generating with temperature 1.5\n",
            "This movie are hopelessly strains seeing ive thats totally this nomination i could was splendid rewind fake youve blah make at scifi high votes actually kate trying aboard rudolf rather the such various originally criticize jumping [UNK] killing talents cutout millions nature [UNK] in with exorcism lungs like cleese hate sadako video\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 365ms/step - loss: 6.1696\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 5.2343== Generating with temperature 0.2\n",
            "This movie movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie deeper this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.5\n",
            "This movie a that murder this movie in was awful a movie end contrasts clerks or old farmhouse this lsd adding movie a even dull a set constraints a hokey true scifi mia a styles nuns just where bored realizing running for half story because verve vampires movie icon a vampire pockets\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 327ms/step - loss: 5.2342\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 5.0254== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.5\n",
            "This movie with with oneliners finishes with poorly viewing with help with with with with window flirting with with with with with with laughoutloud with with with with grain with with with with with with odds with with with kicked cringeworthy with with with with impressively corrupt with with with with with\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 330ms/step - loss: 5.0253\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 4.8727== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this absolutely this this this this this this this this this\n",
            "== Generating with temperature 1.5\n",
            "This movie infamous this this explanation simply this this crazed this this this only this this this this [UNK] who this this this this this this obviously this this this thriller ones like most inspiration this this this  really this this proves this this this this this sun this explains this\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 328ms/step - loss: 4.8726\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 4.7574== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.5\n",
            "This movie enemies mason oh laughing plummer plummer     would  i    repeated        [UNK]           all         cars     \n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 328ms/step - loss: 4.7574\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 4.6598== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.5\n",
            "This movie this became to either fulfill  this force this this this a treasure that shouldve this corrupted this said this this recommended this this really this site right uma movement this this this this this this attempts yet today this this years this this this pay this freedom this this\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 326ms/step - loss: 4.6597\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 4.5798== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie a all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all\n",
            "== Generating with temperature 1.5\n",
            "This movie movie a this integrity so stretches so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so so\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 330ms/step - loss: 4.5797\n",
            "Epoch 8/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 4.5042== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this this this [UNK] all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all\n",
            "== Generating with temperature 1.5\n",
            "This movie part part part part briefly part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part part\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 330ms/step - loss: 4.5042\n",
            "Epoch 9/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 4.4349== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all all\n",
            "== Generating with temperature 1.5\n",
            "This movie tone emotional depicts available owen spontaneous nephew bette black russell rain dances everything demonstrated connected black jonathan grandmother kelly screenings fists andrea it hughes shaped husband revolves truth black stefan thoroughly spreads moving valentino black elegant moore white cain estevez optimism beautifully white drowned moving shoot winters black helpless white\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 328ms/step - loss: 4.4349\n",
            "Epoch 10/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 4.3736== Generating with temperature 0.2\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
            "== Generating with temperature 0.5\n",
            "This movie this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this and this this this this this this this this this this not\n",
            "== Generating with temperature 1.0\n",
            "This movie this this this still and still and still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still still\n",
            "== Generating with temperature 1.5\n",
            "This movie medal the some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some some\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 328ms/step - loss: 4.3735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78aa6e8175e0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Due to limited resources, I could only use the GPU for a short time, allowing me to run the model for just 10 epochs instead of the desired 200 epochs. Consequently, the results were not as expected. The limited number of epochs is the primary reason for the suboptimal model performance."
      ],
      "metadata": {
        "id": "OXAUjuPsonuA"
      }
    }
  ]
}